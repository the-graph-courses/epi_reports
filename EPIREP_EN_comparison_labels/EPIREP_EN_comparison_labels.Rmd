---
title: '\ '
output:
  html_document:
    number_sections: true
    toc: true
    toc_float: true
    css: !expr here::here("global/style/style.css")
    highlight: kate
    pandoc_args: --shift-heading-level-by=-1
  word_document:
    toc: true
editor_options:
  markdown:
    wrap: 100
  canonical: true
  chunk_output_type: console
---

```{r, include = FALSE, warning = FALSE, message = FALSE}
### TEMPLATE FOR EPI REPORTS LESSONS

# require pacman 
if(!require(pacman)) install.packages("pacman")

# Source functions 
source(here::here("global/functions/lesson_functions.R"))

# knitr settings
knitr::opts_chunk$set(warning = F, message = F, class.source = "tgc-code-block", error = T)
```

## Introduction

Welcome to this lesson on group comparisons in data visualization. This is an important topic in data analysis, as it allows us to understand differences and similarities in our data across different segments or groups.

In this lesson, we'll explore a variety of visualization techniques. We'll discuss bar plots for showing frequency among categories, box plots for illustrating data distribution, and we'll touch on error bars and density plots for demonstrating data variability and distribution.

By the end, you'll have a solid understanding of how to use these tools to visualize and compare groups in your data, enhancing your ability to draw meaningful insights from your datasets. Let's get started.

## Learning objectives

By the end of this lesson, you will be able to:

1.  Distinguish between bar plots, column plots, and histograms.
2.  Visualize different summary metrics among different categories and groups.
3.  Implement box plots to illustrate data distribution across various groups.
4.  Apply error bars to represent data variability.

## Packages

For this lesson we will use the {tidyverse} package

```{r}
pacman::p_load(tidyverse)
```

## Data

Next, we'll be working with the `tb` dataset. This dataset comprises tuberculosis (TB) cases recorded over specific periods at certain health facilities. It presents data on the nature of TB cases, the diagnosis type, and the treatment outcomes.

For clarity, let's review the details of each column in our dataset:

1.  **period:** This column records the time frame for each entry in the dataset. The periods are marked quarterly, starting from the first quarter of 2015 (represented as `2015Q1`) up to the last quarter of 2017 (`2017Q4`). This column allows us to track the progression and changes in TB cases over time.

2.  **orgunit:** The `orgunit` column indicates the specific health facility where the TB cases were recorded. These facilities represent different geographical and administrative areas, each with unique characteristics and capabilities. The facilities in the dataset include:

    -   **CS Kalale**
    -   **St Jean De Dieu**
    -   **CHPP Akron**
    -   **CNHU-PPC**
    -   **CS Abomey-Calavi**

    This information can be used to analyze and compare the prevalence and treatment outcomes of TB across different facilities.

3.  **variable_name:** This column categorizes the TB cases based on the diagnosis type and the stage of their treatment journey. Each variable corresponds to a different aspect of the patient's diagnosis and treatment progress:

    - **completed_treatment_cases (newrel_labconf_cmplt / newrel_clindx_cmplt):** These are the TB cases where the treatment has been completed. For bacteriologically confirmed cases, this means the treatment was completed as per protocol. Clinically diagnosed cases indicate the same, but without bacteriological confirmation.
    
    - **cured_cases (newrel_labconf_cur):** This refers to bacteriologically confirmed TB cases that have been cured, with the cure backed by at least two clear sputum smear results post-treatment.
    
    - **died_during_treatment_cases (newrel_labconf_died / newrel_clindx_died):** Represents the TB cases that resulted in the death of the patient during treatment, including both bacteriologically confirmed and clinically diagnosed cases.
    
    - **treatment_failed_cases (newrel_labconf_fail / newrel_clindx_fail):** These are the cases where treatment failed, which is confirmed for bacteriologically tested patients and observed in clinically diagnosed cases.
    
    - **treatment_started_cases (newrel_labconf_coh / newrel_clindx_coh):** Cases that began treatment and are expected to have outcomes reported, excluding those who were moved to second-line treatment.
    
    - **unevaluated_cases (newrel_labconf_neval / newrel_clindx_neval):** These are the TB cases that started treatment but do not have an evaluated treatment outcome available. This applies to both bacteriologically confirmed and clinically diagnosed cases.
    

4.  **diagnosis_type:** This column categorizes the TB cases based on the method of diagnosis. There are two types of diagnosis included in this dataset:

    -   **bacteriologically_confirmed:** These are the cases where the presence of TB bacteria is confirmed through bacteriological examination methods, such as sputum smear microscopy or culture methods.
    -   **clinically_diagnosed:** These are the cases where TB diagnosis is made based on clinical signs and symptoms, without bacteriological confirmation. This usually happens when bacteriological tests are either unavailable or inconclusive, and the patient presents TB symptoms.

5.  **value:** The `value` column contains the count of TB cases for each combination of variable, period, health facility, and diagnosis type. This allows for quantitative analysis of the TB cases, such as the total number of new cases over a specific period or the number of cases that completed treatment in a particular health facility.

By providing a comprehensive view of the TB cases, the dataset facilitates the detailed analysis of the disease's prevalence and progression over time, the effectiveness of different treatment approaches, and the performance of different health facilities in managing and treating TB. This dataset also helps in understanding the distribution of bacteriologically confirmed and clinically diagnosed TB cases.




```{r}
tb <- read_csv(here::here('data', 'clean', 'benin_tb.csv'))
tb
```

## Before we start

As we embark on our exploration, it's crucial to revisit key aspects of `{ggplot2}` that fundamentally influence how we represent variables, perform computations, and manage aesthetics. Understanding these elements not only aids in the creation of visually compelling plots but also ensures that our visualizations accurately reflect the underlying data:

-   The `aes` function plays a pivotal role in mapping our data variables to aesthetic properties in our plots. This determines how the data points are positioned, colored, and sized.
-   The `stat` parameter allows us to specify the type of statistical transformation applied to the data before it's rendered on the plot. Whether we leave the data as is with `stat = "identity"` or calculate case counts with `stat = "count"`, this parameter transforms how our data is visually interpreted.
-   To manage overlapping axis labels due to their length, `{ggplot2}` provides tools like `coord_flip()` to switch the x and y axes, and theme adjustments such as `theme(axis.text.x = element_text(angle = 45))` to tilt the text.
-   Through the `theme_set()` function, we can specify a default theme to ensure a consistent look across all plots in our script.
-   The `labs()` function enables us to refine our plot's title and change axis labels, adding a layer of customization to our visual output.

These tools and functions in `{ggplot2}` form the bedrock of our data visualization journey, guiding us in accurately and intuitively representing our data.

## Understanding Barplots, Col Plots, and Histograms

Choosing the right type of plot is largely determined by the nature of your data and the objective of the analysis. Specific plots such as barplots, histograms, and col plots are designed to handle different data scenarios and analysis needs.

For instance, a barplot is ideal when you wish to compare a numerical variable against a categorical one. In R, this can be accomplished using the `geom_bar()` function from the ggplot2 package. Specifically, if your goal is for ggplot to count the number of rows in your dataset (for example, the number of occurrences of a categorical variable), `geom_bar()` is the function to turn to.

For example let's visualize the number of cases for each treatment:

```{r}
# Begin with the tb dataset
tb |> 
  # Pass the data to ggplot as a basis for creating the visualisation
  ggplot() + 
  #  geom_bar() creates a count plot
  geom_bar(
    # Specify that the x-axis will represent the 'variable_name', 
    aes(x = variable_name)
  ) +
  labs(title = "Number of Cases for Each Treatment")
```

This code is creating a bar plot using the `tb` dataset. The x-axis of the plot represents the different variable names in the `variable_name` column. For each variable, a bar is plotted with its height representing the count of records for that variable, *effectively creating a histogram*.

However, if your data is already summarized or includes specific values for the y-axis (the height of the bars), you should use `geom_col()`. This function is designed to plot pre-calculated values, great for when you have a clear y variable to display against a categorical x variable.
First let's calculate the total number of cases in each period:

```{r}
period_sum <- tb |> 
  # Group the data by 'period'
  group_by(period) |> 
  # For each group, calculate the sum of the 'value' column
  # The na.rm = T argument is crucial as it ensures that missing values (NA's) 
  # are ignored while calculating the sum
  summarise(value = sum(value, na.rm = TRUE))

period_sum
```

Now let's use `period_sum` to visualize each year's total number of cases:

```{r}
period_sum |> 
  # Pass the summarised data to ggplot for visualisation
  ggplot() +
  # Use geom_col() to create a bar plot 
  geom_col(
    # Within aes(), specify that the x-axis will represent the 'period', 
    # the height of the bars (y-axis) will represent the 'value', 
    # and the different 'orgunit' values will be represented by different colors
    aes(x = period, y = value)
  ) + 
  labs(title = "Total Number of Cases Each Period")
```

The `na.rm = TRUE` parameter in the `sum()` function is important because it ensures that any missing values (`NA`) in your data are ignored when calculating the sum. Without this argument, if there are any `NA` values in your data, `sum()` would also return `NA`. So, to get a meaningful result, it's important to include `na.rm = TRUE` when summing data that may contain `NA` values.

::: pro-tip
The `geom_bar()` function in `{ggplot2}` can be utilized to create bar plots, similar to `geom_col()`. However, `geom_bar()` makes the height of the bar proportional to the number of cases in the group (or the count), and is used for creating histogram-like plots. When we want to use `geom_bar()` in the same way as `geom_col()` to represent actual values in the data rather than counts, we need to set the `stat` parameter to `'identity'`. 

```{r}
period_sum |> 
  ggplot() +
  # Use geom_bar() to create a bar plot. Set 'stat' to 'identity' so that the height of the bars represent the actual 'value'
  geom_bar(aes(x = period, y = value), stat = 'identity')
```

In the `aes()` function within `geom_bar()`, we have specified `x = period`, `y = value`. This means that the x-axis will represent the 'period', the height of the bars (y-axis) will represent the `'value'`.
:::

On the other hand, when your data is numeric and continuous, and you're interested in understanding its distribution, the `geom_histogram()` function is the right tool to use. A histogram divides the range of your data into bins and shows the number of observations that fall into each bin. This is particularly useful when you want to inspect the shape, center, and spread of your data, let's see how our data is ditributed:

```{r}
# Begin with the tb dataset
tb |> 
  ggplot() +
  # Use geom_histogram() to create a histogram
  geom_histogram(
    # Within aes(), specify that the x-axis will represent the 'value', 
    # and the different 'orgunit' values will be represented by different colors
    aes(x = value),
    # Set binwidth to 5. This determines the width of the bins in the histogram.
    binwidth = 5
  ) + 
  labs(title = "Distribution of the Data")
```

This code is creating a histogram using the `tb` dataset. The x-axis of the histogram represents the summed values for each combination of 'period' and 'orgunit'. The data is divided into bins of width 5 along the x-axis, and the height of each bar represents the count of records that fall into each bin. 

::: key-point
Remember, the choice between `geom_bar()`, `geom_col()`, and `geom_histogram()` will depend on the structure of your data and the specific insights you wish to extract from your visualization.
:::

## Diving Deeper grouping plots

For data visualization in R, `geom_col()` from the `{ggplot2}` library serves as a robust and flexible function for creating bar plots. When working with categorical data, it offers a broad range of options for generating various types of bar plots, each delivering unique insights into your data. 

While `geom_bar()` provides similar functionality, `geom_col()` offers greater flexibility by directly using the values in the data for the bar heights. This makes it a more versatile choice for a wide array of datasets and visualization needs. 

Given this versatility, we'll continue our exploration focusing primarily on `geom_col()` to understand the creation of different types of bar plots:

1. **Stacked Plots**: By default, `geom_col()` creates stacked bar plots, where each bar is divided into segments representing different sub-categories. The `y` aesthetic is mapped to a variable representing the values you wish to visualize. The `fill` aesthetic is typically mapped to a factor variable representing the sub-categories. The height of each segment within the bar corresponds to the value of each sub-category.

2. **Normalized Stacked Plots (Position Fill Plots)**: `geom_col()` can also create normalized stacked bar plots. These plots are similar to regular stacked plots but with a key difference: the total height of each bar is standardized to the same size, effectively showing proportions rather than counts or absolute values. This is achieved by setting the `position` argument to `"fill"`.

3. **Grouped (Position Dodge) Plots**: `geom_col()` can create grouped bar plots by placing bars for each sub-category side by side. This format facilitates comparisons across categories. You create a grouped bar plot by setting the `position` argument to `"dodge"`.

In summary, `geom_col()` provides a suite of options for visualizing categorical data in different contexts. The choice between stacked, normalized stacked, and grouped plots depends on your data and the insights you want to highlight.
The choice between `geom_bar()` and `geom_col()`, and between stacked, normalized stacked, and grouped plots, depends on the specifics of your data and what you want to emphasize in your visualization.

In the following sub-section we will create these 3 types of plots to visualize difference in groups in our dataset.

### Crafting Stacked Plots

Stacked plots offer a holistic view of category totals while visually segregating contributions from different sub-categories. With `geom_col()`, simply map a variable to the `fill` aesthetic to create divisions in the bars representing your sub-categories. Let's take advantage of this and explore share of cases for each facility in each period

```{r}
# Start with the 'tb' data frame
tb |> 

  # Initiate a ggplot object
  ggplot() + 
  
  # Add a column geom to the plot
  geom_col(
    
    # Define aesthetics within the geom:
    aes(
      x = period,     # Specify 'period' as the variable for the x-axis
      y = value,      # Define 'value' as the variable for the y-axis 
      fill = orgunit  # Use 'orgunit' to color code the bars
    )
  ) +

  # Add a title using labs() function
  labs(
    title = "Share of Cases for Each Facility in Each Time Period"
  )
```

### Designing Normalized Stacked Plots

For a comparative view of sub-category distribution across categories, normalized stacked plots come into play. Here, each bar height is standardized, effectively displaying proportions. Apply the `position = "fill"` argument in `geom_col()` to achieve this. Let's see what is the share of every treatment protocol per year

```{r}
tb |> 
  ggplot() + 
  geom_col(
    aes(
      x = period, 
      y = value,
      fill = variable_name
    ),
    position = 'fill'
  )
```

### Building Grouped (Position Dodge) Plots

Grouped bar plots provide a side-by-side representation of sub-categories within each category, which aids in comparative analysis across categories. Set the `position` argument to `"dodge"` in `geom_col()` to display bars side by side. Let's investigate the difference between healthcare facilities in terms of their diagnosis method. 

```{r}
tb |> 
  ggplot() + 
  geom_col(
    aes(
      x = orgunit, 
      y =  value, 
      fill = diagnosis_type
    ), 
    position = 'dodge'
  )
geom_col(aes(x = category, y = value, fill = subcategory), position = "dodge")
```



## Enhancing Barplots: Adding Error Bars

Visualizing data with error bars allows for a clearer understanding of the variability or uncertainty inherent in the dataset, which is crucial when comparing different groups or conditions. Error bars can indicate the reliability of a mean score or an individual data point, providing context to the plotted values.

To implement error bars in `{ggplot2}`, we use the `geom_errorbar()` function. This requires an understanding of the range of your error, typically defined by the standard deviation, standard error, or confidence intervals.

Here's an example of how to add error bars to a `geom_col()` plot to check out how many treatment cases per year do we have in our data.

First let's create the necessary summary data since we need to have some kind of error measurement, in our case we will compute the standard deviation:

```{r}
p_dt_sum <- tb |> 
  group_by(period, diagnosis_type) |> 
  summarise(
    error = sd(value, na.rm = T),
    value = sum(value, na.rm = T)
  )

p_dt_sum
```

Let's delve into the plot creation process. We start by initializing a ggplot object with `ggplot()` and then layering our plot with `geom_col()` to create the bars, representing each `diagnosis_type` by a different color. Following that, we overlay `geom_errorbar()` to add vertical error bars, which provide a visual indication of variability or uncertainty in our data measurements.


```{r}
# Define the width for dodging
dodge_width <- 0.9

# Create the ggplot with proper dodging
p_dt_sum |> 
  ggplot(aes(
    x = period,
    y = value,
    fill = diagnosis_type,
    group = diagnosis_type  # Ensure proper grouping for dodging
  )) +
  geom_col(position = position_dodge(dodge_width)) +  # Dodge the bars
  geom_errorbar(
    aes(ymin = value - error, ymax = value + error),
    position = position_dodge(dodge_width),  # Dodge the error bars
    width = 0.25  # Set the cap width of the error bars
  )
  

p_dt_sum |> 
  ggplot(aes(
    x = period,
    ymin = value - error, 
    ymax = value + error,
    fill = diagnosis_type,
    group = diagnosis_type  # Ensure proper grouping for dodging
  )) +
  geom_col(aes(y = value), position = position_dodge(), width = 100) +  # Dodge the bars
  geom_errorbar(position = position_dodge())
```

1. We set the groundwork with `p_dt_sum`, specifying how the data will be represented graphically through `aes()`.
2. By using `geom_col()`, we create a column plot, with `position_dodge(0.9)` ensuring that bars corresponding to different `diagnosis_type` within the same `period` are positioned side by side for an easy comparison.
3. `geom_errorbar()` adds the error bars. The `group = diagnosis_type` within `aes()` helps ggplot understand that error bars should align with the respective bars of each diagnosis type. The `position_dodge(0.9)` argument is critical here as it aligns the error bars with the dodged position of the bars, preventing any misalignment.
4. The `width = 0.4` in `geom_errorbar()` specifies the thickness of the error bars, balancing visibility with aesthetics.

Through these steps, we create a clear, informative plot that not only shows the counts of each diagnosis type over time but also incorporates error margins to reflect the uncertainty or variability inherent in our data. This added layer of information is crucial for a nuanced understanding of the dataset, allowing for a more robust data interpretation.

This section enhances bar plots with the addition of error bars using the `geom_errorbar()` function in `{ggplot2}`. Error bars provide crucial insight into the variability or uncertainty within the dataset, aiding comparisons across groups or conditions. After computing necessary summary data (including error measurement via standard deviation), a column plot is created with `geom_col()`. This is followed by the addition of error bars using `geom_errorbar()`, with the range defined by the sum value plus or minus the error. Positioning is carefully handled to ensure accurate representation and clear visualization, particularly when there are multiple categories for a single period. In summary, error bars augment bar plots by encapsulating variability, enhancing data comprehension.

## Exploring New Forms: Area Plots


In this section, we'll be exploring area plots with `geom_area()`. These plots are especially advantageous for visualizing a range of data values or the progression of data across time, making them ideal for use cases like tracking stock prices or climate changes and in our case the quarterly treatment cases.

In order to do this we need to summarise our data so we have the sum of cases for every treatment case per quarter:

```{r}
p_vn_sum <- tb |> 
  group_by(period, variable_name) |>    # Group data by 'period' and 'variable_name'
  summarise(
    value = sum(value, na.rm = T)    # Summarise the data by calculating the sum of 'value', removing NAs
  )
p_vn_sum
```

Now we can use this data to make our area plot as follows:

```{r}
# Area Plot
p_vn_sum |> 
ggplot(
  aes(
    x = period,    # Map 'period' to the x-axis
    y = value,     # Map 'value' to the y-axis
    fill = variable_name    # Map 'variable_name' to the fill aesthetic
  )
) +
  geom_area(stat = "identity")    # Add an area plot to the graph
```

In this code, we first group the `tb` data frame by `period` and `variable_name`, and then summarize the `value` by calculating the sum for each group (ignoring NAs). This summarized data is then used to create a ggplot area plot, with `period` as the x-axis, `value` as the y-axis, and the `variable_name` determining the fill of the areas.

In summary, area plots, specifically those created with `geom_area()`, are powerful tools for visualizing data progression over time or for displaying ranges of values. They shine in scenarios where understanding trends or changes over time is key.



## Venturing into Circular Plots: Pie Charts and Donut Plots

::: watch-out
As we venture into the section on donut and pie charts, it's important to note that we don't generally endorse the use of these chart types. While they may appear visually appealing, they often lead to less accurate interpretations compared to other chart types, such as bar plots. The primary issue lies in the way humans interpret visual information. It's much easier for us to compare the lengths of bars (as in a bar plot) than it is to compare angles or areas (as in pie or donut charts). Furthermore, when data categories increase, pie or donut charts can become cluttered and confusing. They also lack the capacity to show changes over time, a feature effectively communicated by bar plots. Therefore, while donut and pie charts have their place in data visualization, they should be used judiciously, considering their limitations in accurately conveying complex data.
:::


In this section, we will delve into circular data visualizations, particularly pie charts and donut plots, to demonstrate categorical data distribution. These types of plots can be quite polarizing in the data visualization community due to their tendency to distort data interpretation. However, when employed judiciously, they can offer an intuitive snapshot of proportions within a dataset.

Before we can visualize the data, we must first aggregate it to get the total counts for each treatment outcome category, ensuring we have a clear representation of each segment of our dataset.

```{r}
# Aggregate data by treatment outcome
vn_sum <- tb |>
  group_by(variable_name) |>    # Categorize data by treatment outcome
  summarise(value = sum(value, na.rm = TRUE))  # Sum values, ignore NAs
vn_sum
```
In this code, `group_by()` function categorizes our data by the `variable_name`, which represents different TB treatment outcomes. The `summarise()` function then aggregates the data, computing the sum of the `value` column for each category, ensuring that any missing values (`NA`) are excluded from the calculation (`na.rm = TRUE`).

Now, let's initialize our ggplot object for the pie chart creation:

```{r}
# Initialize ggplot object for pie chart
donut <- ggplot(vn_sum, aes(x = factor(1), fill = variable_name, y = value)) +  # Map aesthetics to data
  geom_bar(stat = "identity", width = 1) +  # Create bars with width 1
  coord_polar(theta = "y") +  # Transform to polar coordinates for pie chart
  theme_void() +  # Apply a minimalistic theme
  labs(fill = "Treatment Outcome")  # Label the fill aesthetic
donut
```
This chunk begins with `ggplot()`, setting up our data and aesthetics within the `aes()` function. The `geom_bar()` with `stat = "identity"` tells ggplot to take the values as they are, without attempting to count or bin them, and `width = 1` ensures each bar spans the full width of the plot space. Applying `coord_polar()` then transforms our bar plot into a circular pie chart by mapping the length of the bars (their `y` values) into angles and radii within a circle. `theme_void()` removes the background, grids, and axes, offering a clean pie chart, and `labs()` assigns a label to our fill aesthetic for clarity in the legend.

To enhance our visual analysis, we'll transform the pie chart into a donut plot. A donut plot is essentially a pie chart with a central void, offering a distinct visual format that can sometimes aid in the comparative assessment of data segments. The creation of a donut plot from a pie chart is achieved by introducing a visual element that masks the center of the pie, leaving a ring-shaped display.

```{r}
# Modify pie chart to create a donut plot
donut +
  geom_rect(aes(xmin = -1, xmax = 1, ymin = -1, ymax = 1), fill = "white")  # Add white circle for donut hole
```
In this final transformation, the `geom_rect()` function is crucial, it overlays a white rectangle onto our plot, which, due to the polar transformation, appears as a circle. This effectively 'cuts out' the center of the pie chart, resulting in the donut appearance. The aesthetics (`aes()`) for `geom_rect()` are set to span the entire plot area, ensuring that the white circle covers the center and creates the donut effect.

By adding this inner white circle, we change the perception of the data by providing a centralized focal point, which can sometimes help in comparing the proportions of each segment by providing a common boundary for visual reference.

To summarize, while pie and donut charts can be visually appealing, they are best used sparingly and in specific contexts, such as comparing parts of a whole for a single category with few segments. Their primary limitation is the difficulty in comparing angles or areas, especially as the number of categories increases.

## Wrap Up! {.unnumbered}


This lesson provides a comprehensive journey through data visualization utilizing R and `{ggplot2}`. We start with the basics, introducing bar plots, column plots, and histograms - these are foundational tools for visualizing data trends.

Next, the lesson explores more complex techniques, such as grouping data in various ways: stacked plots, normalized stacked plots, and grouped plots. These methods allow for more detailed comparisons within your data.

Enhancements to bar plots are then covered, specifically the addition of error bars. These provide important insights into the variability of data, which can be critical when comparing different groups or conditions.

The lesson also introduces `geom_ribbon()` and area plots. These are useful for showcasing a range of values or visualizing data over time.

Finally, we delve into the world of circular plots, learning how to create pie charts and donut plots. These are effective ways to represent proportional data.

In summary, this lesson gives a well-rounded understanding of various data visualization techniques, empowering students to effectively communicate data stories using R and `{ggplot2}`.

## Solutions {.unlisted .unnumbered}


## Contributors {.unlisted .unnumbered}

The following team members contributed to this lesson:

```{r echo = F}
# This function uses information stored in global/contributors/contributors.csv
# Only team members who contributed "substantially" to a specific lesson should be listed here
# See https://tinyurl.com/icjme-authorship for notes on "substantial" contribution
.tgc_contributors_list(
  ids = c(
    "Bennour",
    "joy"
  ))
```

## References {.unlisted .unnumbered}

Some material in this lesson was adapted from the following sources:



<!-- (Chicago format. You can use https://www.citationmachine.net) -->

`{r} .tgc_license()`
